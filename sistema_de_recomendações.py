# -*- coding: utf-8 -*-
"""Sistema de Recomendações

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17SmOrLN94bI12a-xvUrLmcw5eEJmfVDH

Autor: Pedro Lucas Ferreira da Silva
Linkedin: https://www.linkedin.com/in/pedrs/
Email: pedrolucasferreira555@gmail.com
"""

#hide
from google.colab import drive
drive.mount('/content/drive')

# Instalar e configurar o Kaggle
!pip install -q -U kaggle
!pip install --upgrade --force-reinstall --no-deps kaggle
!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Commented out IPython magic to ensure Python compatibility.
# #Hide
# %%writefile kaggle.json
# {"username":"<your kaggle username>","key":"<your kaggle api key>"}

##Baixar e descompactar o conjunto de dados de imagens de produtos de moda
!kaggle datasets download -d paramaggarwal/fashion-product-images-small
!unzip fashion-product-images-small.zip

#Organizar imagens em catecorias
import pandas as pd
from shutil import move
import os
from tqdm import tqdm

#Criar Diretório para Armazenar
os.mkdir('/content/Fashion_data')
os.chdir('/content/Fashion_data')

#Verificar se o arquivo CSV existe
df = pd.read_csv('/content/styles.csv', usecols=['id','masterCategory']).reset_index()
df['id'] = df['id'].astype('str')

#Lista todos as imagens
all_images = os.listdir('/content/images/')
co = 0
os.mkdir('/content/Fashion_data/categories')

#Mover Rotular as imagens movendo para sas respectivas categorias
for image in tqdm(all_images):
    category = df[df['id'] == image.split('.')[0]]['masterCategory']
    category = str(list(category)[0])
    if not os.path.exists(os.path.join('/content/Fashion_data/categories', category)):
        os.mkdir(os.path.join('/content/Fashion_data/categories', category))
    path_from = os.path.join('/content/images', image)
    path_to = os.path.join('/content/Fashion_data/categories', category, image)
    move(path_from, path_to)
    co += 1
print('Moved {} images.'.format(co))

#Pré processamento de imagem
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

#Listar as Classes
categories = os.listdir('/content/Fashion_data/categories')

# Definir parâmetros para os geradores de dados
datagen_kwargs = dict(rescale=1./255, validation_split=.20)
dataflow_kwargs = dict(target_size=(224, 224), batch_size=32, interpolation="bilinear")

# Gerador de dados de validação
valid_datagen = ImageDataGenerator(**datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(
    '/content/Fashion_data/categories', subset="validation", shuffle=False, **dataflow_kwargs)

# Gerador de dados de treinamento com ou sem aumento de dados
do_data_augmentation = False
if do_data_augmentation:
    train_datagen = ImageDataGenerator(
        rotation_range=40,
        horizontal_flip=True,
        width_shift_range=0.2, height_shift_range=0.2,
        shear_range=0.2, zoom_range=0.2,
        **datagen_kwargs)
else:
    train_datagen = valid_datagen

train_generator = train_datagen.flow_from_directory(
    '/content/Fashion_data/categories', subset="training", shuffle=True, **dataflow_kwargs)

#Criar Modelo e treinar
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense

# Construir o modelo usando Functional API
input_layer = Input(shape=(224, 224, 3))
base_model = ResNet50(weights="imagenet", include_top=False, input_tensor=input_layer)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.2)(x)
x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)
x = Dropout(0.2)(x)
output_layer = Dense(len(categories), activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)

model = Model(inputs=input_layer, outputs=output_layer)
model.summary()

# Definir otimizador e função de perda
lr = 0.003 * 32 / 512
SCHEDULE_LENGTH = 500
SCHEDULE_BOUNDARIES = [200, 300, 400]

# Decaimento da taxa de aprendizado
lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES,
                                                                   values=[lr, lr*0.1, lr*0.01, lr*0.001])
optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)

loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)

model.compile(optimizer=optimizer,
              loss=loss_fn,
              metrics=['accuracy'])

# Treinar o modelo
steps_per_epoch = train_generator.samples // train_generator.batch_size
validation_steps = valid_generator.samples // valid_generator.batch_size

hist = model.fit(
    train_generator,
    epochs=7,
    steps_per_epoch=steps_per_epoch,
    validation_data=valid_generator,
    validation_steps=validation_steps
).history

#Salvamento de modelo
keras_file = "/content/model.keras"
tf.keras.models.save_model(model, keras_file)

# Avaliar o modelo nos dados de validação
loss, accuracy = model.evaluate(valid_generator, steps=validation_steps)

print(f"Acurácia: {accuracy}")
print(f"Perda: {loss}")

# Imprimir outras métricas, se disponíveis no histórico de treinamento
if 'val_loss' in hist and 'val_accuracy' in hist:
    print(f"Perda de validação: {hist['val_loss'][-1]}")
    print(f"Acurácia de validação: {hist['val_accuracy'][-1]}")

#Recomendar com base no acesso
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import euclidean_distances
from tensorflow.keras.models import Model, load_model

# Definir parâmetros para os geradores de dados
datagen_kwargs = dict(rescale=1./255)
dataflow_kwargs = dict(target_size=(224, 224), batch_size=32, interpolation="bilinear", class_mode=None, shuffle=False)

# Gerador de dados
datagen = ImageDataGenerator(**datagen_kwargs)
generator = datagen.flow_from_directory(
    '/content/Fashion_data/categories', **dataflow_kwargs)

# Carregar o modelo já treinado
base_model = load_model('/content/model.keras')

# Função para extrair embeddings
def extract_embeddings(model, generator):
    embeddings = model.predict(generator, verbose=1)
    return np.array(embeddings)

# Função para recomendar imagens semelhantes
def recommend_similar_images(query_image_index, embeddings, top_n=5):
    query_embedding = embeddings[query_image_index].reshape(1, -1)
    distances = euclidean_distances(query_embedding, embeddings).flatten()
    similar_indices = np.argsort(distances)[:top_n + 1]  # +1 para incluir a própria imagem
    return similar_indices[1:]  # Excluir a própria imagem

# Função para exibir imagens semelhantes
def plot_similar_images(query_image_index, similar_indices, generator):
    # Exibir imagem de consulta
    plt.figure(figsize=(5, 5))
    query_image = generator[query_image_index // generator.batch_size][query_image_index % generator.batch_size]  # Ajuste para acessar a imagem corretamente
    plt.imshow(query_image)
    plt.title(f"Consulta ({query_image_index})")
    plt.axis("off")
    plt.show()

    # Exibir imagens recomendadas
    for i, idx in enumerate(similar_indices):
        plt.figure(figsize=(5, 5))
        similar_image = generator[idx // generator.batch_size][idx % generator.batch_size]  # Ajuste para acessar a imagem corretamente
        plt.imshow(similar_image)
        plt.title(f"Similar {i+1} ({idx})")
        plt.axis("off")
        plt.show()

# Extração de embeddings
embeddings = extract_embeddings(base_model, generator)

# Testar o sistema
query_index = 18  # Índice da imagem de consulta
similar_images = recommend_similar_images(query_index, embeddings)
plot_similar_images(query_index, similar_images, generator)
